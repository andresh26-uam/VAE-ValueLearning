{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1aefdeba",
            "metadata": {
                "id": "intro-cell",
                "language": "markdown"
            },
            "source": [
                "# Learning the value systems of societies from preferences - submitted for ECAI 2025\n",
                "This notebook is designed to execute the experiments for the ECAI paper titled \"Learning the value systems of societies from preferences\". The paper presents a novel approach to learning value systems (value-based preferences) and value groundings (domain-specific value alignment measures) of a society of agents or stakeholders from examples of pairwise preferences between alternatives in a decision-making problem domain.\n",
                "\n",
                "In the paper we utilize the Apollo dataset from [](https://rdrr.io/cran/apollo/man/apollo_swissRouteChoiceData.html), about train choice in Switzereland. The dataset includes features such as cost, time, headway, and interchanges, which are used to model agent preferences based on values. Although it also works for sequential decision making, in the paper we focus on the non-sequential decision making use case that the Apollo Dataset is about. \n",
                "\n",
                "There are three main executables:\n",
                "- **`generate_dataset_non_sequential.py`**: Generates the dataset for the experiments.\n",
                "- **`train_vsl_non_sequential.py`**: Trains the reward models using the generated dataset. This script supports running multiple seeds in parallel.\n",
                "- **`evaluate_results.py`**: Evaluates the trained models and generates plots to visualize the results.\n",
                "\n",
                "This notebook is divided into three main sections:\n",
                "1. **Dataset Generation**: Generates the Apollo dataset.\n",
                "2. **Training**: Trains the reward models using a certain number of seeds in parallel.\n",
                "3. **Evaluation**: Evaluates the results and displays the plots directly in the notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "130ed26e",
            "metadata": {
                "id": "dataset-generation",
                "language": "markdown"
            },
            "source": [
                "## 1. Dataset Generation\n",
                "In this section, we generate the Apollo dataset using the `generate_dataset_one_shot_tasks.py` script. This dataset will be used for training and evaluation in subsequent steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "dedb552f",
            "metadata": {},
            "outputs": [],
            "source": [
                "BASE_SEED = 26 # Actual seed in the paper is 26\n",
                "N_SEEDS = 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "2f600c18",
            "metadata": {
                "id": "generate-dataset",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/generate_dataset_one_shot_tasks.py:97: DeprecationWarning: Nesting argument groups is deprecated.\n",
                        "  pc_group = alg_group.add_argument_group(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Namespace(dataset_name='ecai_apollo', gen_trajs=True, gen_preferences=True, dtype=<class 'numpy.float32'>, algorithm='pc', config_file='algorithm_config.json', environment='apollo', seed=26, test_size=0.0, reward_epsilon=0.0)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.routes_train to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.routes_train` for environment variables or `env.get_wrapper_attr('routes_train')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.routes_test to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.routes_test` for environment variables or `env.get_wrapper_attr('routes_test')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1125.08 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2436.11 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3509.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1317.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 799.08 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3033.25 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2050.61 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2663.61 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2643.56 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3830.80 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 998.45 examples/s] \n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3171.76 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3078.51 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2797.14 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3237.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1864.09 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2763.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3263.20 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3118.44 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2680.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2950.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2836.44 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2412.14 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1436.92 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3093.27 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2529.57 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2566.20 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2799.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2086.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2737.99 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2769.23 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3061.16 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2029.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2176.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2459.04 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3311.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1979.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2774.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1793.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1286.46 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2707.07 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1573.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2244.94 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2720.24 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3143.37 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3115.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1867.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2420.95 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1695.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2267.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2248.09 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2297.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1631.46 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1674.60 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2048.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2491.09 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2478.33 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3054.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1988.45 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3473.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2527.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2322.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3471.47 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3943.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2845.42 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2596.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2668.98 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2801.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3072.75 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2969.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3096.95 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3514.94 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3074.25 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2452.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1306.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3567.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3054.97 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3128.39 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2263.59 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1620.12 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2655.56 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1142.48 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2076.79 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2579.17 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3026.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1878.09 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2041.30 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3014.59 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2306.82 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3322.37 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2814.65 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2981.61 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3201.76 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1758.33 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1950.99 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2235.44 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2629.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2695.47 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2365.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1325.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 936.61 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2940.16 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1957.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2564.10 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1709.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3034.95 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1889.18 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2879.06 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1543.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2776.97 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2076.39 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2636.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2079.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2865.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2538.84 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2328.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1679.40 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1411.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2483.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2814.76 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2998.07 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3218.82 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2661.17 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2945.44 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3412.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3370.27 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3038.98 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2643.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1185.00 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2718.08 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1519.12 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3037.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3079.02 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3162.33 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2450.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3022.20 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3446.27 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3368.92 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3653.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2677.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2778.71 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2494.05 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3020.50 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2898.18 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2350.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3140.36 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3117.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3307.67 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2601.21 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3206.79 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1961.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2271.56 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2328.59 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3674.92 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3508.90 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2966.39 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2902.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3468.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2925.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3074.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 935.56 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1761.24 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3101.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2643.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1711.53 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1529.56 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3360.67 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2959.99 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2522.38 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3072.13 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3126.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2534.15 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2665.49 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2656.86 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2241.61 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1928.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1885.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2096.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3450.21 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2683.40 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1793.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3408.46 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3758.71 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3217.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3116.90 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3331.60 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3631.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3008.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3013.15 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3069.00 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1710.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1301.52 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2568.81 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2805.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2764.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2516.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2688.18 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2726.82 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2350.77 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1758.66 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2998.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2791.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3534.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2882.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1229.84 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2841.24 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3272.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3603.70 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1517.08 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2238.49 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3313.18 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1580.50 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3623.07 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1426.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3510.86 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3216.08 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3128.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2048.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2581.02 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3451.00 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2649.78 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3452.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1081.47 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2261.89 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3273.82 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3029.23 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2611.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1304.92 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 754.88 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3333.37 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3096.57 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2332.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2005.09 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2797.14 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3024.74 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2848.53 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2684.64 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2289.81 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2869.43 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2831.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3317.40 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1532.57 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3062.90 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3558.01 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2485.51 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3056.58 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2081.94 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2049.45 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2766.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1575.06 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2667.76 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2299.79 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3350.23 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3190.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2880.81 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2601.84 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3561.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3121.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3374.04 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2630.30 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2293.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3515.60 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3159.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3100.64 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3090.11 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2626.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3217.86 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2822.23 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1907.18 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3408.31 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3484.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2877.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2543.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2860.84 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2517.17 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3288.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3753.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2433.52 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3616.82 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2976.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3331.46 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2565.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3346.37 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2453.93 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3245.67 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2741.38 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3466.21 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 533.54 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3266.31 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1858.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2170.28 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3253.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1470.45 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2554.21 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2779.01 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3366.97 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1913.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2833.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3462.23 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1687.74 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1983.49 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1813.40 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1889.00 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2629.66 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2134.51 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2665.87 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2383.50 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3030.20 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2722.20 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3010.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3064.27 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2968.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3537.67 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3301.45 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3223.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2882.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3225.15 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3419.42 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1678.95 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3099.75 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3452.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3075.50 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3405.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2366.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2025.64 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2179.74 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1485.73 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1175.02 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2823.92 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2852.19 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2090.13 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1714.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1316.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1454.31 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2807.22 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3211.97 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2462.33 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 893.74 examples/s] \n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2618.26 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1734.62 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2479.72 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3413.55 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1885.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1568.35 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3229.29 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3402.63 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3733.62 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2106.51 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3238.01 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2108.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1623.85 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3701.40 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3440.30 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3423.30 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1583.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 944.10 examples/s] \n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2755.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3010.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2882.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1689.96 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3009.91 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2875.33 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 936.17 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2303.58 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1846.94 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3497.03 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3025.83 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2254.53 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2565.50 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1942.96 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2796.00 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3230.94 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3353.21 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2854.02 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2576.62 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3055.96 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2347.41 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2944.06 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3045.24 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2753.57 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2389.46 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2707.65 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1805.38 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 3447.69 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1605.71 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1150.68 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 1120.24 examples/s]\n",
                        "Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 2563.67 examples/s]\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_ids_train to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_ids_train` for environment variables or `env.get_wrapper_attr('agent_ids_train')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.agent_ids_test to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.agent_ids_test` for environment variables or `env.get_wrapper_attr('agent_ids_test')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.preferences_per_agent_id to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.preferences_per_agent_id` for environment variables or `env.get_wrapper_attr('preferences_per_agent_id')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.preferences_grounding_per_agent_id to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.preferences_grounding_per_agent_id` for environment variables or `env.get_wrapper_attr('preferences_grounding_per_agent_id')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_reward_per_align_func to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_reward_per_align_func` for environment variables or `env.get_wrapper_attr('get_reward_per_align_func')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n",
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.basic_profiles to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.basic_profiles` for environment variables or `env.get_wrapper_attr('basic_profiles')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "TESTING DATA COHERENCE. It is safe to stop this program now...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/andresh26/Desktop/VAE-ValueLearning/ValueLearningFromPreferences/.venv/lib/python3.13/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.reward_matrix_per_align_func to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward_matrix_per_align_func` for environment variables or `env.get_wrapper_attr('reward_matrix_per_align_func')` that will search the reminding wrappers.\u001b[0m\n",
                        "  logger.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset generated correctly.\n",
                        "CRETING DATASET FOR AGENTS:  ['14831', '21120', '18762', '15246', '17727', '14951', '14992', '17525', '14010', '20808', '23497', '22762', '20161', '20149', '19904', '79809', '21492', '22616', '15904', '12931', '23939', '9364', '13608', '14167', '18991', '20836', '19251', '16176', '15319', '15318', '18614', '13972', '16188', '15481', '14576', '23480', '17645', '12729', '17876', '20572', '22403', '14823', '17443', '17669', '12063', '19888', '17655', '15056', '17906', '22003', '23321', '14572', '76862', '22599', '21912', '12670', '19902', '16204', '15296', '13181', '18942', '22410', '18968', '18997', '21694', '12712', '21509', '20818', '13034', '16617', '13784', '21044', '19295', '77558', '19901', '12049', '22820', '12713', '19646', '19691', '20010', '12505', '22439', '22377', '21619', '20063', '12748', '82401', '15147', '22933', '80438', '18852', '16116', '16102', '14700', '16117', '18674', '14728', '12359', '78194', '22265', '23147', '17779', '14264', '23386', '17037', '22067', '19422', '14845', '15597', '23233', '18272', '15030', '17169', '20128', '15805', '20100', '77919', '22930', '15420', '15408', '16101', '18893', '18878', '13508', '17975', '23352', '15970', '22662', '15780', '19353', '16060', '19409', '23024', '21623', '20298', '15948', '17187', '15009', '15814', '17971', '25041', '16448', '14539', '10213', '19237', '23197', '14074', '21756', '22277', '16461', '20676', '23586', '14458', '16298', '14100', '16930', '22473', '16926', '21620', '21146', '22498', '22881', '17190', '17609', '20304', '13916', '13902', '23157', '12375', '12407', '82028', '17230', '16106', '13718', '77275', '22506', '82559', '19745', '15180', '25043', '16489', '76584', '15792', '23220', '82613', '16927', '13863', '15562', '23205', '15012', '17177', '12741', '22682', '15827', '5641', '18697', '23629', '15402', '12423', '14735', '19239', '16863', '22278', '20094', '18251', '15563', '19398', '16929', '11934', '15213', '19401', '15978', '15039', '80546', '18509', '20109', '23372', '16493', '14509', '15603', '20323', '15373', '14723', '21955', '12409', '16690', '16684', '18859', '22092', '20108', '17834', '21835', '14642', '22455', '24785', '13883', '19438', '18040', '15982', '17159', '79045', '17788', '75131', '19028', '15174', '18875', '81503', '19203', '14727', '14041', '20469', '24627', '20455', '16454', '19001', '23362', '16497', '21818', '13869', '20521', '80781', '16907', '22644', '18255', '17600', '21577', '20696', '13506', '21749', '21952', '13062', '18650', '21947', '13922', '20697', '21589', '19002', '16480', '15572', '21199', '84525', '22309', '16090', '22321', '13831', '13602', '16020', '12534', '14353', '14421', '22583', '14742', '73901', '15312', '16169', '18805', '84392', '21712', '21289', '15662', '24440', '22186', '21458', '22384', '15266', '18967', '16989', '21857', '16590', '19890', '17739', '14967', '23885', '15489', '77581', '22580', '14754', '21922', '16195', '84391', '12640', '17710', '17937', '18219', '24286', '18557', '13199', '23066', '14802', '23062', '21846', '14619', '14369', '84197', '14553', '13214', '22220', '22208', '14751', '14023', '82040', '14787', '16184', '14208', '22779', '17926', '17107', '15704', '23507', '79386', '18778', '14817', '18785', '20597', '19470', '23934', '13607', '19855', '22169', '24281', '16569', '22035', '21500', '24487', '19712', '17717', '14785', '20352', '78677', '20391', '22586', '12445', '16178', '19539', '2439', '22961', '11429', '23464', '14419', '15707', '12901', '24525', '13389', '19868', '12083', '16971', '18790']\n",
                        "TRAIN SIZE 3492\n",
                        "CRETING DATASET FOR AGENTS:  []\n",
                        "TEST SIZE 0\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import os\n",
                "# Use the gentr flag to generate the information of trajectories/alternatives.\n",
                "# Use the genpf flag to generate the preferences between trajectories/alternatives.\n",
                "os.system(f'python generate_dataset_one_shot_tasks.py --environment apollo --dataset_name ecai_apollo --seed {BASE_SEED} -gentr -genpf')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c54f3a11",
            "metadata": {
                "id": "training-section",
                "language": "markdown"
            },
            "source": [
                "## 2. Training\n",
                "In this section, we train the reward models using the `train_vsl_non_sequential.py` script. We run the training process with `N_SEEDS` different seeds in parallel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f11913ba",
            "metadata": {
                "id": "training",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Process SpawnPoolWorker-3:\n",
                        "Process SpawnPoolWorker-2:\n",
                        "Process SpawnPoolWorker-1:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
                        "    return _ForkingPickler.loads(res)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
                        "AttributeError: Can't get attribute 'train_with_seed' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
                        "    return _ForkingPickler.loads(res)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
                        "AttributeError: Can't get attribute 'train_with_seed' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
                        "    return _ForkingPickler.loads(res)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
                        "AttributeError: Can't get attribute 'train_with_seed' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
                        "Process SpawnPoolWorker-4:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
                        "    return _ForkingPickler.loads(res)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
                        "AttributeError: Can't get attribute 'train_with_seed' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
                        "Process SpawnPoolWorker-5:\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
                        "    return _ForkingPickler.loads(res)\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
                        "AttributeError: Can't get attribute 'train_with_seed' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
                        "Process SpawnPoolWorker-10:\n",
                        "Process SpawnPoolWorker-9:\n",
                        "Process SpawnPoolWorker-8:\n",
                        "Process SpawnPoolWorker-6:\n",
                        "Process SpawnPoolWorker-7:\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
                        "    with self._rlock:\n",
                        "         ^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "KeyboardInterrupt\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
                        "    self.run()\n",
                        "    ~~~~~~~~^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
                        "    self._target(*self._args, **self._kwargs)\n",
                        "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
                        "    task = get()\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 384, in get\n",
                        "    with self._rlock:\n",
                        "         ^^^^^^^^^^^\n",
                        "  File \"/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/synchronize.py\", line 95, in __enter__\n",
                        "    return self._semlock.__enter__()\n",
                        "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
                        "KeyboardInterrupt\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Run training in parallel\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;28mlen\u001b[39m(seeds)) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_with_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:367\u001b[39m, in \u001b[36mPool.map\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    363\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[33;03m    in a list that is returned.\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "from multiprocessing import Pool\n",
                "\n",
                "def train_with_seed(seed):\n",
                "    import os\n",
                "    # The -O option is important, as there are many costly debugging operations in the code\n",
                "    os.system(f\"python -O train_vsl_non_sequential.py --dataset_name ecai_apollo -ename ecai_test_s{seed} -s={seed} -e apollo -cf='algorithm_config_L3.json\")\n",
                "\n",
                "# List of seeds to run in parallel\n",
                "seeds = [26 + i for i in range(N_SEEDS)]\n",
                "\n",
                "# Run training in parallel\n",
                "with Pool(len(seeds)) as pool:\n",
                "    pool.map(train_with_seed, seeds)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "27a90499",
            "metadata": {
                "id": "evaluation-section",
                "language": "markdown"
            },
            "source": [
                "## 3. Evaluation\n",
                "In this section, we evaluate the trained models using the `evaluate_results.py` script. The evaluation will generate plots to visualize the results, and these plots will be displayed directly in the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d43ea7d7",
            "metadata": {
                "id": "evaluation",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "seed = 26\n",
                "experiments_all_seeds = ','.join([f\"ecai_test_{seed+i}\" for i in range(N_SEEDS)])\n",
                "\n",
                "os.system(f\"python evaluate_results.py -ename ecai_test_{seed} --lrcfrom={experiments_all_seeds}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
