{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1aefdeba",
            "metadata": {
                "id": "intro-cell",
                "language": "markdown"
            },
            "source": [
                "# Learning the value systems of societies from preferences - submitted for ECAI 2025\n",
                "This notebook replicates the experiments for the ECAI paper titled \"Learning the value systems of societies from preferences\". The paper presents a novel approach to learning value systems (value-based preferences) and value groundings (domain-specific value alignment measures) of a society of agents or stakeholders from examples of pairwise preferences between alternatives in a decision-making problem domain.\n",
                "\n",
                "In the paper we utilize the Apollo dataset from [https://rdrr.io/cran/apollo/man/apollo_swissRouteChoiceData.html](https://rdrr.io/cran/apollo/man/apollo_swissRouteChoiceData.html), about train choice in Switzereland. The dataset includes features such as cost, time, headway, and interchanges, which are used to model agent preferences based on values. Although it also works for sequential decision making, in the paper we focus on the non-sequential decision making use case that the Apollo Dataset is about. \n",
                "\n",
                "There are three main executables:\n",
                "- **`generate_dataset_non_sequential.py`**: Generates the dataset for the experiments.\n",
                "- **`train_vsl_non_sequential.py`**: Trains the reward models using the generated dataset. This script supports running multiple seeds in parallel.\n",
                "- **`evaluate_results.py`**: Evaluates the trained models and generates plots to visualize the results.\n",
                "\n",
                "This notebook is divided into three main sections:\n",
                "1. **Dataset Generation**: Generates the Apollo dataset.\n",
                "2. **Training**: Trains the reward models using a certain number of seeds in parallel.\n",
                "3. **Evaluation**: Evaluates the results and displays the plots directly in the notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "130ed26e",
            "metadata": {
                "id": "dataset-generation",
                "language": "markdown"
            },
            "source": [
                "## 1. Dataset Generation\n",
                "In this section, we generate the Apollo dataset using the `generate_dataset_one_shot_tasks.py` script. This dataset will be used for training and evaluation in subsequent steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dedb552f",
            "metadata": {},
            "outputs": [],
            "source": [
                "BASE_SEED = 26 # Actual seed in the paper is 26\n",
                "N_SEEDS = 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f600c18",
            "metadata": {
                "id": "generate-dataset",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "# Use the gentr flag to generate the information of trajectories/alternatives.\n",
                "# Use the genpf flag to generate the preferences between trajectories/alternatives.\n",
                "os.system(f'python generate_dataset_one_shot_tasks.py --environment apollo --dataset_name ecai_apollo --seed {BASE_SEED} -gentr -genpf')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c54f3a11",
            "metadata": {
                "id": "training-section",
                "language": "markdown"
            },
            "source": [
                "## 2. Training\n",
                "In this section, we train the reward models using the `train_vsl_non_sequential.py` script. We run the training process with `N_SEEDS` different seeds in parallel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "971cb479",
            "metadata": {},
            "outputs": [],
            "source": [
                "K_tests = [1,2,3,6,9,12]\n",
                "\n",
                "# List of seeds to run in parallel\n",
                "seeds = [BASE_SEED + i for i in range(N_SEEDS)]\n",
                "\n",
                "def train_with_seed(seed, K):\n",
                "    import subprocess\n",
                "    # The -O option is important, as there are many costly debugging operations in the code\n",
                "    subprocess.Popen(f\"python -O train_vsl_non_sequential.py --dataset_name ecai_apollo -ename ecai_test_K{K}_s{seed} -s={seed} -e apollo -cf='algorithm_config_K{K}.json'\", shell=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3765ec8f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training in parallel as separate processes\n",
                "for K in K_tests:\n",
                "    # Create a separate process for each seed and K\n",
                "    processes = [train_with_seed(seed, K) for seed in seeds]\n",
                "# Train will take approximately 2-6 hours for each L in a small MACBook Pro M2.\n",
                "# It is slow because it does not scale very well in the number of agents (the algorithm can be subject to more technical optimizations)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "304142e2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# If want to run all K and seeds in parallel, you can use the following command:\n",
                "if False:\n",
                "    processes = [train_with_seed(seed, K) for seed in seeds for K in K_tests]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "27a90499",
            "metadata": {
                "id": "evaluation-section",
                "language": "markdown"
            },
            "source": [
                "## 3. Evaluation\n",
                "In this section, we evaluate the trained models using the `evaluate_results.py` script. The evaluation will generate plots to visualize the results, and these plots will be displayed directly in the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4c17b52",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "seed = 26\n",
                "\n",
                "experiments_all_seeds_per_K = {K: ','.join([f\"ecai_test_{seed+i}_K{k}\" for i in range(N_SEEDS)]) for k in K_tests}\n",
                "experiments_all = ','.join([f\"ecai_test_K{K}_s{seed}\" for K in K_tests for seed in seeds])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7282c86e",
            "metadata": {},
            "source": [
                "This will produce the tables and plots for a specific seed and maximum number of clusters. The results of each execution will be saved in the `test_results/ecai_test_s{seed}_K{K}` directory.\n",
                "Inside, there will be:\n",
                "\n",
                "- `train_set/`: The results over training set (there is no test set in this case, in other environments it might be useful). Inside there are the following folders:\n",
                "  - `explanations/`: Morris sensitivity analysis of the grounding functions.\n",
                "  - `plots/`: Plots of different kinds.\n",
                "    - `context_features/`: It shows in a graphical manner the proportional deviation from the mean of the context features affecting each decision in each cluster. (e.g. going for shopping, business, etc.)\n",
                "    - `hists_clusters.pdf`: Shows pie charts of every value system, and histograms for the representativeness achieved in each cluster.\n",
                "    - `figure_clusters.pdf`: A graphical representation of the clusters. Given the distances are not euclidean, it is not very informative, but it is useful to see how the clusters are separated visually and how well each agent is internally represented each agent (inside the circles). To better see the latter, the `hists_clusters.pdf` is more useful.\n",
                "  - `tables/`: Results that are better shown in table-form. Tables are in CSV and LaTeX format. They are represented for each single cluster assignment in the final state of the memory used during training, stating the position in the ranking (ordered first by grounding coherence, then by dunn index score).\n",
                "    - `context_features/`: These tables show the grpahical representation of the context features from before, adding the actual averages of each feature per cluster and the global ones.\n",
                "    - `general/`: These tables show general information about the assignments: number of agents per cluster, value system, Dunn index, grounding coherence, representativeness, etc.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fb97dcbe",
            "metadata": {},
            "outputs": [],
            "source": [
                "for K in K_tests:\n",
                "    for seed in seeds: # (optional)\n",
                "        os.system(f\"python evaluate_results.py -ename ecai_test_s{BASE_SEED}_K{K}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a86f1802",
            "metadata": {},
            "source": [
                "This calcutes the learning curves for each maximum number of clusters, aggregating the curves of the different seeds used. The results for each maximumm of clusters K are saved at `test_results/ecai_test_s{BASE_SEED}_K{K}/learning_curves/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b729e48e",
            "metadata": {},
            "outputs": [],
            "source": [
                "for K in K_tests:\n",
                "    os.system(f\"python evaluate_results.py -ename ecai_test_s{BASE_SEED}_K{K} --lrcfrom={experiments_all_seeds_per_K[K]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "029f3460",
            "metadata": {},
            "source": [
                "This calculates the Dunn Index curve comparing the executions with different maximum number of clusters. Each point represents number of \"predicted clusters/maximum number of clusters permitted\", and the graph shows the average Dunn Index over the number of cases each combination happened to be the final best solution in all the experiments (taking into account all the different execution seeds). The results for each maximumm of clusters K are saved at `test_results/ecai_test_s{BASE_SEED}_K{K}/di_scores/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d43ea7d7",
            "metadata": {
                "id": "evaluation",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "os.system(f\"python evaluate_results.py -ename ecai_test_{seed} --dicfrom={experiments_all}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
