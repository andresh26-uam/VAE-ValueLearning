{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1aefdeba",
            "metadata": {
                "id": "intro-cell",
                "language": "markdown"
            },
            "source": [
                "# Learning the value systems of societies from preferences - submitted for ECAI 2025\n",
                "This notebook is designed to execute the experiments for the ECAI paper titled \"Learning the value systems of societies from preferences\". The paper presents a novel approach to learning value systems (value-based preferences) and value groundings (domain-specific value alignment measures) of a society of agents or stakeholders from examples of pairwise preferences between alternatives in a decision-making problem domain.\n",
                "\n",
                "In the paper we utilize the Apollo dataset from [](https://rdrr.io/cran/apollo/man/apollo_swissRouteChoiceData.html), about train choice in Switzereland. The dataset includes features such as cost, time, headway, and interchanges, which are used to model agent preferences based on values. Although it also works for sequential decision making, in the paper we focus on the non-sequential decision making use case that the Apollo Dataset is about. \n",
                "\n",
                "There are three main executables:\n",
                "- **`generate_dataset_non_sequential.py`**: Generates the dataset for the experiments.\n",
                "- **`train_vsl_non_sequential.py`**: Trains the reward models using the generated dataset. This script supports running multiple seeds in parallel.\n",
                "- **`evaluate_results.py`**: Evaluates the trained models and generates plots to visualize the results.\n",
                "\n",
                "This notebook is divided into three main sections:\n",
                "1. **Dataset Generation**: Generates the Apollo dataset.\n",
                "2. **Training**: Trains the reward models using a certain number of seeds in parallel.\n",
                "3. **Evaluation**: Evaluates the results and displays the plots directly in the notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "130ed26e",
            "metadata": {
                "id": "dataset-generation",
                "language": "markdown"
            },
            "source": [
                "## 1. Dataset Generation\n",
                "In this section, we generate the Apollo dataset using the `generate_dataset_one_shot_tasks.py` script. This dataset will be used for training and evaluation in subsequent steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f600c18",
            "metadata": {
                "id": "generate-dataset",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "!python generate_dataset_one_shot_tasks.py --environment apollo --dataset_name apollo_data --seed 26"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c54f3a11",
            "metadata": {
                "id": "training-section",
                "language": "markdown"
            },
            "source": [
                "## 2. Training\n",
                "In this section, we train the reward models using the `train_vsl_non_sequential.py` script. We will run the training process with 5 different seeds in parallel to ensure robustness and reproducibility of the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7fd7648",
            "metadata": {},
            "outputs": [],
            "source": [
                "N_SEEDS = 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f11913ba",
            "metadata": {
                "id": "training",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "from multiprocessing import Pool\n",
                "\n",
                "def train_with_seed(seed):\n",
                "    import os\n",
                "    os.system(f\"python train_vsl_non_sequential.py -dname apollo_data -ename ecai_apollo_s{seed} --seed {seed} --max_iter 5000 --environment apollo\")\n",
                "\n",
                "# List of seeds to run in parallel\n",
                "seeds = [26 + i for i in range(N_SEEDS)]\n",
                "\n",
                "# Run training in parallel\n",
                "with Pool(len(seeds)) as pool:\n",
                "    pool.map(train_with_seed, seeds)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "27a90499",
            "metadata": {
                "id": "evaluation-section",
                "language": "markdown"
            },
            "source": [
                "## 3. Evaluation\n",
                "In this section, we evaluate the trained models using the `evaluate_results.py` script. The evaluation will generate plots to visualize the results, and these plots will be displayed directly in the notebook."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d43ea7d7",
            "metadata": {
                "id": "evaluation",
                "language": "python"
            },
            "outputs": [],
            "source": [
                "!python evaluate_results.py --experiment_name ecai_apollo -lrcfrom  --show_plots"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
