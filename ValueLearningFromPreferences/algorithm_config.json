{
"ff": {
        "name": "FireFighters-v0",
        "n_values": 2,
        "K": 3,
        "horizon": 50,
        "basic_profiles": [[1.0, 0.0], [0.0,1.0]],
        "profiles_colors": [[1,0,0], [0,0,1]],
        "feature_selection": "features_one_hot",
        "initial_state_distribution": "random",
        "environment_is_stochastic": true,
        "discount": 1.0,
        "use_pmovi_expert": false,
        "default_reward_net": {
            "use_state": true,
            "use_action": true,
            "use_next_state": false,
            "use_done": false,
            "basic_layer_classes": ["nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "ConvexAlignmentLayer"],
            "activations": ["nn.LeakyReLU", "nn.LeakyReLU", "nn.Tanh", "nn.Tanh", "nn.Identity"],
            "use_bias": [true, true, true, false, false],
            "hid_sizes": [50, 100, 50, 2],
            "negative_grounding_layer": false,
            "clamp_rewards": false
        },
        "reward_feature_extractor": "FeatureExtractorFromVAEnv",
        "policy_state_feature_extractor": "OneHotFeatureExtractor",
        "_options_for_feature_extractors": ["FeatureExtractorFromVAEnv", "OneHotFeatureExtractor", "ObservationMatrixFeatureExtractor"],
        "default_optimizer_kwargs": {
            "lr": 0.001,
            "weight_decay": 0.0000,
            "betas": [0.0, 0.1]
        },
        "default_optimizer_class": "Adam",
        "algorithm_config": {
            "pc": {
                "reward_net": {},
                "optimizer_kwargs": "default",
                "optimizer_class": "default",
                "learn_stochastic_policy": true,
                "loss_class": "cross_entropy",
                "loss_kwargs": {},
                "_loss_class_options": ["cross_entropy_modified", "cross_entropy"],
                "active_fragmenter_on": "random",
                "discount_factor_preferences": 1.0,

                "policy_approximation_method": "mce_original",
                "_policy_approximation_method_options": ["mce_original", "new_value_iteration", "use_learner_class"],

                "approximator_kwargs": {"value_iteration_tolerance": 0.0000001, "iterations": 2000},
                "use_quantified_preference": false,
                "preference_sampling_temperature": 0,
                "query_schedule": "hyperbolic",
                "train_kwargs": {
                    "max_iter": 10000,
                    "trajectory_batch_size": 1000,
                    "fragment_length": "horizon",
                    "imitation_iterations": 200,
                    "initial_comparison_frac": 0.15,
                    "initial_epoch_multiplier": 50,
                    "transition_oversampling": 1
                },

                "learner_policy_class": "PPO",
                "learner_policy_kwargs" : 
                {
                    "batch_size": 25,
                    "n_steps": 50,
                    "ent_coef": 0.1,
                    "learning_rate": 0.02,
                    "gamma": 1.0,
                    "gae_lambda": 0.999,
                    "clip_range": 0.05,
                    "vf_coef": 0.01,
                    "n_epochs": 5,
                    "normalize_advantage": true,
                    "tensorboard_log": "./ppo_tensorboard_expert_ff/"
                },
                
                "reward_trainer_kwargs": {
                    "epochs": 5,
                    "batch_size": 512
                }
            }
        }
    }
    
}